\documentclass{ieeeaccess}
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{algorithm2e}
\usepackage{multirow}
\usepackage{bm}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}
%\history{Date of publication xxxx 00, 0000, date of current version xxxx 00, 0000.}
\history{}
%\doi{10.1109/ACCESS.2017.DOI}
\doi{}

\title{Recent Research Progress on Cognition Capabilities of Service Robots}
\author{\uppercase{Hecheng Zhao}\authorrefmark{1},
\uppercase{Yuan Li\authorrefmark{2}, and Sukhan Lee}.\authorrefmark{3},
\IEEEmembership{Fellow, IEEE}}
\address[1]{Intelligent System Research Institute (ISRI),
Sungkyunkwan University, 16419, Suwon, South Korea (e-mail: hczhao@skku.edu)}
\address[2]{Benewake Co., Ltd., Beijing, China (ly@benewake.com)}
\address[3]{Intelligent System Research Institute (ISRI),
Sungkyunkwan University, 16419, Suwon, South Korea (e-mail:
lsh@ece.skku.ac.kr)}
%\tfootnote{This paragraph of the first footnote will contain support 
%information, including sponsor and financial support acknowledgment. For 
%example, ``This work was supported in part by the U.S. Department of 
%Commerce under Grant BS123456.''}

%\markboth
%{Author \headeretal: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS}
%{Author \headeretal: Preparation of Papers for IEEE TRANSACTIONS and JOURNALS}

\corresp{Corresponding author: Sukhan Lee (e-mail: lsh@ece.skku.ac.kr).}

\begin{abstract}
This report summarizes the works which have been presented by the Intelligent Systems Research Institute of Sungkyunkwan University to the community of artificial intelligence and robotics. Five relevant articles published by the Institute during 2015 to 2018 are reviewed in order to exhibit the research progress made on cognitive capabilities of service robots. The Major Line Extraction algorithm has been proposed to exploit line features of the environments. This novel algorithm exhibits an improvement on extracting cursive lines with less discontinuities. Experimental results have shown that the algorithm outperforms a well-known method called the Line Segment Detector. Additionally, the Covariance Projection Filtering is a sensor filtering framework proposed for distributed sensory systems. The framework generalizes a filtering model for Gaussian linear systems. Comparing with Kalman filters, it provides an additional step for detecting data anomalies. For indoor environments, Wi-Fi fingerprints are of available landmarks for localizing robot positions. A new approach has been proposed based on the concept of "invariant received signal length statistics" that is able to overcome the instability of Wi-Fi signals. Experimental results show that this new method provides higher performance by 17\% in terms of success rate. For object detection, a new method has been proposed for detecting industrial objects with less textures. The method employees model-based point cloud matching within an adaptive Bayesian framework. Experiments show that such an approach achieves over 97.5\% of recognition rate. Later, a deep neural network has been integrated into such a framework. It adopts a Convolutional Neural Network based feature extraction and reconstruction model to handle a larger number of objects without performance degeneration. It turns out that such a method allows the number of objects and their categories to be extended by 10 and 5 times, respectively.
\end{abstract}

\begin{keywords}
Covariance Projection Filtering, Feature Extraction, Line Segment Detection, Object Recognition, Pose Estimation, Simultaneous Localization and Mapping, Semantic Understanding.
\end{keywords}

\titlepgskip=-15pt

\maketitle

\section{Major Line Extraction}
\label{sec:introduction}
\subsection{Summary}
The novelty of the proposed method\cite{7031358} lies in the framework
of recruiting major lines from the maximally generated zero
threshold Canny edge links with the Sobel highlights as a guide
for recruitment. This makes it easier not only for representing
lines as a whole in terms of connected edge clusters but also
for tracing cursive lines of a higher curvature along Sobel highlights, resulting in a better way of incorporating a wider scope of
global context and of optimizing the sensitivity and robustness
trade-off.

\subsection{Methodology}
To obtain the Sobel highlights from
an input image, $I_0$, and its min-max normalized Sobel image, $I_s$,
first, at each pixel, a $3\times n$ oblong shape mask is defined along the
direction of its Sobel edge orientation with the pixel at the center,
as shown in Figure \ref{oblong}

\Figure[t!](topskip=0pt, botskip=0pt, midskip=0pt){oblong.png}
{An oblong shape mask placed for a pixel.\label{oblong}}.

Major lines tend
to have their lengths sufficiently long. The longer the length,
the better the chance of the edge link is being a major line. The
length index, $w_l$, is defined by
\begin{equation}
w_l=log_N(number\ of\ the\ pixels\ of\ a\ link).
\end{equation}

The above three indices, $w_c$, $w_a$, and $w_l$, quantifying for the
potential of a zero-threshold Canny edge link as a major line,
are now combined into a single index, $w$, referred to here as the
recruitment index, as follows:
\begin{equation}
w=w_{l}w_{c}^{\alpha}w_{\alpha}^{\beta},
\end{equation}
where the parameters, $\alpha$ and $\beta$, are to be used for setting the
relative significance between $w_c$ and $w_a$.

Finally, a zero-threshold Canny edge link is selected as a
major line, if the recruitment index, $w$, is larger than the pre-set
threshold. Note that, in this letter, $\alpha$ and $\beta$ are both set as 0.5 as
the default values and the recruitment index threshold is set as
1.0. For more detailed flow of the proposed algorithm, refer to
the following pseudo-code.
\begin{algorithm}
\caption{L-K Algorithm: A Major Line Segment Extraction}
\SetAlgoLined
\textbf{Input}: An Original Image $L$\\
\textbf{Output}: Line Segment $L$ \\
$I_{S}\leftarrow SobleImage(I)$ \\
$I_{E}\leftarrow CannyEdgeImage(I)$ \\
$E\leftarrow EdgeLinking(I_E)$ \\
\For {$i=0$ to $Sizeof(E)$} {
	\If {$E_i < T_i$ (default: $T_i = 6$)} {
		Continue	
	}
	$B[Sizeof(E_i)][n]\leftarrow$Set Double Array ($n$: oblong mask size) \\
	\For {$j=0$ to $Sizeof(E_i)$} {
		$P_j0, P_j1, P_j2\leftarrow$3 groups of pixel in oblong mask \\
		$\sigma_1\leftarrow$Orientation $Stdev(P_j1)$ \\ 
		$\mu_0, \mu_1, \mu_2\leftarrow$Intensity $Average(P_j0, P_j1, P_j2)$ \\
		\If {$\sigma_1>\rho$ (default: $\rho=15.0$)} {
			Continue		
		}
		\If {not ($\mu_0<\mu_1<\mu_2$ or $\mu_2<\mu_1<\mu_0$)} {
			Continue		
		}
		\For {$k=0$ to $n$} {
			$B[j][k]\leftarrow$Accumulate Sobel highlight score		
		}
	}
	$w_L\leftarrow log_n Sizeof(E_i)$ \\
	$w_c\leftarrow \frac{Sizeof(B[i])}{Sizeof(E_i)}$ \\
	$w_a\leftarrow log_n\frac{Sumof(B[i])}{Sizeof(B[i])}$ \\
	$w\leftarrow w_Lw_{c}^{\alpha}w_{\alpha}^{\beta}$ (default: $\alpha=\beta=0.5$) \\
	\If {$w>T_2$ (default: $T_2=1.0$)} {
		$L_i\leftarrow$Line Segment	
	}
}
\end{algorithm}

\subsection{Results}
To evaluate the performance of the proposed method in comparison with LSD, a top performance major line detector currently available, a major line extraction experimentation is carried out with the test images taken directly from the laboratory,
as shown in Figure \ref{mle_result_a}.

%\Figure[t!](topskip=0pt, botskip=0pt, midskip=0pt){mle_result_a.png}
%{The results of major lines extracted by the proposed
%method.\label{mle_result_a}}

\begin{figure}[t!]
\centering
\includegraphics[width=0.4\textwidth]{mle_result_a.png}
\label{mle_result_a}
\caption{The results of major lines extracted by the proposed
method.}
\end{figure}

The indices computed for
the proposed method and LSD are tabulated in Table \ref{mle_table}. 

\begin{table}
\caption{The performance analysis of the proposed method and LSD with
the coverage and the coverage per major line indices.}

\label{mle_table}
\setlength{\tabcolsep}{3pt}
\centering
\begin{tabular}{|c|c|c|c|c|}
\hline
\multirow{2}{*}{Major Lines} & \multicolumn{2}{l|}{Coverage} & \multicolumn{2}{l|}{Coverage per Major Line} \\ \cline{2-5} 
                             & Proposed         & LSD        & Proposed                & LSD                \\ \hline
Straight                     &   69\%               &     46\%       &          41\%               &                   38\% \\ \hline
Curved                      &     89\%         &     79\%     &         38\%            &           11\% \\ \hline
Combined                      &    76\%       &     58\%     &      40\%             &               19\% \\ \hline
\end{tabular}
\label{tab1}
\end{table}

\section{The Covariance Projection Framework}
\subsection{Summary}
The proposed method\cite{cpf}, referred to here as the Covariance Projection (CP) method, provides an
unbiased and optimal solution in the sense of minimum mean square error (MMSE), if the projection
is based on the minimum weighted distance on the constraint manifold. The proposed method
not only offers a generalization of the conventional formula for handling constraints and data
inconsistency, but also provides a new insight into data fusion in terms of a geometric-algebraic
point of view.
\subsection{Methodology}
he proposed method first represents the probability of true states and measurements in the
extended space around the data from state predictions and sensor measurements, where the extended
space is formed by taking states and measurements as independent variables. Any constraints among
true states and measurements that should be satisfied are then represented as a constraint manifold
in the extended space. This is shown schematically in Figure \ref{cpf_manifold} for filtering as an example. Data fusion is accomplished by projecting the probability distribution of true states
and measurements onto the constraint manifold.

%\Figure[t!](topskip=0pt, botskip=0pt, midskip=0pt){cpf_manifold.png}
%{Probability of true states and measurements in the extended space around the data from
%state predictions and sensor measurements and constraint manifold.\label{cpf_manifold}}

\begin{figure}[t!]
  \centering 
  \includegraphics[width=0.4\textwidth]{cpf_manifold.png}
  \caption{Probability of true states and measurements in the extended space.}
  \label{cpf_manifold}
\end{figure}

More specifically, consider two mean estimates, $\hat{x}_1$ and $\hat{x}_2$, of the state $x\in \mathbb{R}^N$, with their
respective covariances as $P_1, P_1\in \mathbb{R}^N\times N$. Furthermore, the estimates are assumed to be correlated with
cross-covariance $P_{12}$. The mean estimates and their covariances together with their cross-covariance in
$\mathbb{R}^N$ are then transformed to an extended space of $\mathbb{R}^{2N}$ along with the linear constraint between the two estimates:
\begin{equation}
\hat{x}=\begin{bmatrix}
\hat{x}_1 \\ \hat{x}_2
\end{bmatrix},\ P=\begin{bmatrix}
P_1 & P_{12} \\ P_{12}^T & P_2
\end{bmatrix},\ C_1\hat{x}_1=C_2\hat{x}_2
\end{equation}

To find a point on the constraint manifold with minimum weighted distance, we apply the whitening transform (WT) defined as, $W=D^{-1/2}E^T$, where $D$ and $E$ are the eigenvalue and eigenvector matrices of $P$. Applying WT,
\begin{equation}
\hat{x}^W=W\hat{x},\ P^W=WPW^T,\ M^W=WM
\end{equation}

where the matrix $M = [C1 C2]^T$ is the subspace of the constraint manifold. The probability
distribution is then orthogonally projected on the transformed manifold $M^W$ to satisfy the constraints
between the data sources in the transformed space. Inverse WT is applied to
obtain the fused mean estimate and covariance in the original space,
\begin{equation}
\label{xwprw}
\tilde{x}=W^{-1}P_r W\hat{x}
\end{equation}
\begin{equation}
\label{pwprprtwt}
\tilde{P}=W^{-1}P_r P_{r}^{T}W^{-T}
\end{equation}
where $P_r=M^W(M^{W^T}M^W)^{-1}M^{W^T}$ is the orthogonal projection matrix. Using the definition of various
components in (\ref{xwprw}) and (\ref{pwprprtwt}), a close form simplification can be obtained as,
\begin{equation}
\label{xmmtpmmtpx}
\tilde{x}=M(M^TP^{-1}M)^{-1}M^TP^{-1}\hat{x}
\end{equation}
\begin{equation}
\label{pmmtpmmt}
\tilde{P}=M(M^TP^{-1}M)^{-1}M^T
\end{equation}

Due to the projection in extended space of $\mathbb{R}^{2N}$, (\ref{xmmtpmmtpx}) and (\ref{pmmtpmmt}) provide a fused result with respect to each data source. In the case of where $\hat{x}_1$ and $\hat{x}_2$ estimate the same entity, that is, $M=[I_N I_N]^T$, the fused result will be same for the two data sources. As such, a close form equation for fusing redundant data sources in $\mathbb{R}^N$ can be obtained from (\ref{xmmtpmmtpx}) and (\ref{pmmtpmmt}) as,
\begin{equation}
\tilde{x}=(M^TP^{-1}M)^{-1}M^TP^{-1}\hat{x}
\end{equation}
\begin{equation}
\tilde{P}=(M^TP^{-1}M)^{-1}
\end{equation}
\subsection{Results}
The simulation is carried out for 1000 Monte Carlo runs and the local estimates provided by four
sensor nodes along with the fused result of the CP method are shown in Figure \ref{cpf_result_image}. The straight lines
in Figure \ref{cpf_result_image} denote the trace of error covariance matrices and the solid curve represents the MSE of
local and fused estimates. It can be observed from Figure \ref{cpf_result_image} that the MSE of the individual sensor node fluctuates around the trace. Furthermore, the accuracy relation of
local sensor estimates and fused estimates in terms of MSE in Figure \ref{cpf_result_image} is coincident with the
theoretical result in Table \ref{cpf_result_table}.

\begin{figure}[t!]
\centering
\caption{The mean square error (MSE) and trace ($P_i$).}
\label{cpf_result_image}
\includegraphics[width=0.4\textwidth]{cpf_result_image.png}
\end{figure}

\begin{table}
\centering
\begin{tabular}{lllll}
\hline
\multirow{2}{*}{\textbf{Methods}} & \multicolumn{4}{l}{\textbf{Average RMSE}} \\ \cline{2-5} 
                  &     \textbf{$x_1$ (m)} & \textbf{$x_2$ (m)}     &  \textbf{$\dot{x}_1$ (m/s)}   &  \textbf{$\dot{x}_2$ (m/s)}  \\ \hline
             Unconstrained     &   95.479  &   87.496  &   52.413  &  49.972  \\
               CP   &  50.39   &   29.093  &  36.624   &  21.145  \\
               EP(I)   &   55.823  &  32.229   &  39.648   &  22.891  \\
               EP(${P^{u^{-1}}}$)   &  53.023   &   30.613  &   37.186  &  21.469  \\ \hline
\end{tabular}
\label{cpf_result_table}
\caption{Average RMSE for 1000 Monte Carlo Runs.}
\end{table}

\section{Wi-Fi Fingerprinting Based Indoor Localization}
\subsection{Summary}
The instability of Wi-Fi received signal strength (RSS) incurred
by mutable channel characteristics hampers a wide-spread
adoption of RSS based location fingerprinting to real world indoor
localization applications. To overcome RSS instability, we
propose a new approach based on the concept of “invariant RSS
statistics”. By invariant RSS statistics, we mean the RSS samples
collected at each calibration location, especially, under minimal
random spatiotemporal disturbances. The proposed method\cite{Husen:2016:HPI:2857546.2857589} forms
the reference pattern classes for individual calibration locations
with the invariant RSS statistics thus obtained. Fingerprinting is
done by identifying the reference pattern class that maximally
supports the RSS readings collected at an unknown location for
available Wi-Fi sources. The support of RSS readings is defined
here as the sum of the likelihood probabilities of individual RSS
readings. Unlike conventional methods, the proposed method
allows only those readings high in statistical confidence to
participate in the sum, while excluding other readings. This is to
screen out the influence of those readings contaminated by timevarying disturbances on classification. Experimental results show
that the proposed method provides superior performance to
conventional ones with the success rate higher by 17\%, the
printing resolution finer by 30\% and, naturally, no performance
degradation in time without recalibration.

\subsection{Methodology}
The $m$ dimensional Received Signal Strength (RSS) vector,
$\{\mathbf{s}_i(t)\}_j$, at time $t$ at a particular calibration location $j$ due to m Wi-Fi sources, $i=1, …, m$, is represented as
\begin{equation}
\{\mathbf{s}_i(t)\}_j=\{\mathbf{s}_{1,j}(t), \mathbf{s}_{2,j}(t),...,\mathbf{s}_{i,j},...,\mathbf{s}_{m,j}(t)\},\ j=1,...,n
\end{equation}

where the bold-face letter, $\mathbf{s}$, is to represent it as a random
variable.

Here, we model $\mathbf{s}_{i,j}(t)$, the RSS from the $i^{th}$ Wi-Fi source at the $j^{th}$
calibration location, as
\begin{equation}
\mathbf{s}_{i,j}(t)=\bm{\alpha}_{i,j}(t)\times r_{i,j}+\bm{\delta}_{i,j}
\end{equation}
where $r_{i,j}$ represents the time-invariant RSS with no
spatiotemporal disturbances present, $\bm{\alpha}_\{i,j\}(t)$ the multiplicative
signal alteration factor due to the spatiotemporal disturbances of
$r_{i,j}$, and $\bm{\sigma}_{i,j}$ the sensor noise. 

\subsection{Results}
The location of the experimentation is in the $6^{th}$ floor of Research
Complex 2, Sungkyunkwan University, South Korea. The
experimentation area is approximately 350 square meters, which
consists of a few rooms and hallway. We preset seven calibration
locations to begin with (we add more calibration locations as the
research progresses), where it is the spot that has been used to
collect the readings of the Wi-Fi RSS data. Figure \ref{wifi_setup} depicts the
floor map of the experimental area with 14 calibration locations
(Loc. 1 to Loc. 14).

\begin{figure}[t!]
\centering
\label{wifi_setup}
\includegraphics[width=0.5\textwidth]{wifi_setup.png}
\caption{The experiment floor map area with marked
calibration locations}
\end{figure}

The result as depicted in Figure \ref{wifi_result} shows that after 18 weeks, the
conventional approach degrades 14\% in success rate, while our
approach maintains the identical performance. In between week
12 and 13, we recalibrate location fingerprint of the conventional
approach and create a new database out of it, at the same time we
still keep the older database. After week 12, we observed that our
approach still conserve high performance results. On the contrary,
the success rate of the older location fingerprint of conventional
approach continues to deteriorate further. As for the new location
fingerprint after recalibration of the conventional approach,
although the success rate rise to 77\%, it is still significantly lower
than the proposed approach, and continues to deteriorate in the
following weeks. We conclude that our approach performs not
only better in performance, but also stable as time goes by.

\begin{figure*}[t!]
\centering
\label{wifi_result}
\includegraphics[width=0.7\textwidth]{wifi_result.png}
\caption{Time-based performance comparison with
recalibration applied to conventional approach.}
\end{figure*}

Table \ref{wifi_table} illustrates the comparison results to the existing
approaches. We observed that our invariant RSS approach
produced a higher success rate and stable regardless of the number
of samples over different length of time. On the contrary, the
conventional approach and the remove useless Wi-Fi sources
approach suffers from success rate degradation as the number
of samples increased over time. From our analysis, the reason
behind this result is our approach only takes invariant RSS which
maintain low variance although as time increased, as opposed to
existing approaches that takes all available RSS which increased
the variance by longer time.

\begin{table}
\label{wifi_table}
\setlength{\tabcolsep}{3pt}
\centering
\begin{tabular}{c | c c c}
\hline
 & Invariant RSS & Remove Useless Source & Conventional \\
\hline
 n=100 / (2 hours) & 92 & 73 & 71 \\
 n=200 / (1 week) & 94 & 68 & 62 \\
 n=300 / (2 weeks) & 91 & 58 & 52 \\
\hline
\end{tabular}
\caption{Performance comparison with different number of
samples collected over different time length.}
\end{table}

\section{Adaptive Bayesian Recognition}
\subsection{Summary}
Visual recognition and pose estimation of 3D
industrial objects are challenging due to variations of geometric
shapes from perspectives while lacking textures. We propose an approach\cite{7750717} to accurately recognizing industrial
objects and estimating their poses based on an adaptive
Bayesian framework with optimal feature selection and
model-based point cloud matching. First, feature sets that
provide sufficient evidences for recognition are selected from a
predefined pool of features based on the t-test. Then, the
evidence structure for Bayesian framework is updated
adaptively to the feature sets selected for recognition. Finally, a
process of coarse-fine pose estimation, composed of 3D feature
based coarse registration followed by Octree-ICP based model
matching for precision registration, is presented.
\subsection{Methodology}
Proposed framework mainly consists of two parts: 1) 3D
object recognition with multiple evidences. 2) model-based
3D object pose estimation. In recognition process, candidate
evidences include global and local features are extracted from
RGB-D data, i.e. 3D SIFT, CLB and shape descriptor, which
describe object’s texture and general shape. After
collecting candidate features, we apply t-test based feature
selection to choose sufficient features for different target
object as supporting evidences. Lastly, the measured features
are compared with each object in database using Bayesian
network. The object with high probability is considered as the
recognition result. For recognized object, 3D line registration
and 3D SIFT are used for the initial pose estimation. If both
are available, the one with higher confidence would be
adopted based on their registration accuracy. Then,
Octree-ICP is employed to get the refined pose estimation.

\begin{figure*}[t!]
\centering
\includegraphics[width=0.6\textwidth]{bayesian_framework.png}
\caption{Framework overview}
\end{figure*}

After detecting CLB, we could get the number and their
position in 3D space. To describe object using CLB, we would
build a statistical model including CLB’s number and relative
positions between CLBs based on different view-point data.
For single object, there can exists more than one CLB,
however, it is impossible to observe all the surface of an object
at the same time. We have to estimate the CLB feature existing
in one frame data. Regarding CLB’s number, it is not difficult
to understand this model. For relative positions, we would
store all the observed distances between any two detected
CLB in a list for each object and set the detection accuracy as
the variance.

The object probability consists of two parts:
\begin{equation}
F(CLB;u_{num},\Sigma_{num})=e^{-\frac{1}{2}(x-\mu)^T\Sigma^{-1}(x-\mu)}
\end{equation}
\begin{equation}
F(CLB;u_{dis},\Sigma_{dis})=max\ e^{-\frac{1}{2}(x-\mu)^T\Sigma^{-1}(x-\mu)}%,\ \mu\in u_{dis},\ \Sigma\in\Sigma_{dis}
\end{equation}
\begin{equation}
F(CLB)=F(CLB;u_{num},\Sigma_{num})*F(CLB;u_{dis},\Sigma_{dis})
\end{equation}
where $u_{num}$, $\Sigma_{num}$ is the mean and variance of number of
matched CLB for target object; $u_{dis}$ stored all the observed
distances between any two detected CLB in object surface,
while $\Sigma_{dis}$ is the measurement accuracy of CLB.

For measured features, we will apply a Gaussian function
to derive object sufficiency probability. By repeated
measurements, we could calculate the uncertainty existing in
each 3D shape descriptor, and has a better understanding of
this feature’s stability under measurement environment.

Prior probability:
\begin{equation}
F(shape\ descriptor;\mu_{obj},\Sigma_{obj})=\frac{1}{c}e^{-\frac{1}{2}(x-\mu)^T\Sigma^{-1}(x-\mu)}
\end{equation}

where $\mu$, $\Sigma$ is the mean and variance of specific shape
descriptor.
\subsection{Results}
Using robot arm, we move or rotate each target object 10
times, then capture the point cloud for pose estimation. Since
robot arm can offer object’s position as ground truth, the
object’s location from pose estimation is calculated and
compared.

\begin{table}
\setlength{\tabcolsep}{3pt}
\centering
\begin{tabular}{| c | c | c | c | c | c | c | c |}
\hline
\multirow{2}{*}{\textbf{Object}} & \multirow{2}{*}{\textbf{error}} & X  & Y & Z & rX & rY  & rZ  \\
 & & (mm) & (mm) & (mm) & (Deg) & (Deg) & (Deg) \\
\hline
\textbf{mouse}  & mean & 2.472 & 0.632 & 1.912 & 0.556 & 0.148 & 0.513 \\ \cline{2-8}
\textbf{part 1} & Std & 0.943 & 1.672 & 0.552 & 0.442 & 0.197 & 0.199 \\
\hline
\textbf{mouse} & mean & 0.232 & 1.368 & 0.379 & 0.252 & 0.122 & 0.118 \\ \cline{2-8}
\textbf{part 2} & Std & 0.66 & 0.617 & 0.903 & 0.164 & 0.062 & 0.161 \\
\hline
\textbf{mouse} & mean & 0.174 & 0.097 & 0.151 & 0.111 & 0.037 & 0.148 \\ \cline{2-8}
\textbf{part 3} & Std & 0.133 & 0.039 & 0.141 & 0.107 & 0.049 & 0.042 \\
\hline
\textbf{Baby} & mean & 0.316 & 0.645 & 0.06 & 1.526 & 1.327 & 0.984 \\ \cline{2-8}
\textbf{Control PCB} & Std & 1.357 & 0.34 & 0.293 & 1.299 & 0.227 & 0.202 \\ 
\hline
\textbf{Projector} & mean & 0.226 & 0.356 & 0.053 & 0.283 & 0.055 & 0.48 \\ \cline{2-8}
\textbf{Control PCB} & Std & 0.212 & 0.151 & 0.385 & 0.165 & 0.246 & 0.181 \\
\hline
\multirow{2}{*}{\textbf{Clamp}} & mean & 0.446 & 0.416 & 0.172 & 0.524 & 1.645 & 1.614 \\ \cline{2-8}
& Std & 0.067 & 0.441 & 0.185 & 1.233 & 0.521 & 1.254 \\
\hline
\multirow{2}{*}{\textbf{Mater}} & mean & 0.26 & 0.221 & 0.184 & 0.327 & 0.836 & 0.971 \\ \cline{2-8}
& Std & 0.074 & 0.259 & 0.686 & 0.737 & 0.718 & 0.277 \\
\hline
\multirow{2}{*}{\textbf{Saw}} & mean & 0.679 & 0.621 & 1.073 & 0.382 & 1.138 & 1.567 \\ \cline{2-8}
& Std & 0.791 & 0.245 & 0.097 & 1.44 & 1.632 & 0.531 \\
\hline
\textbf{Alternater} & mean & 0.937 & 0.194 & 0.126 & 0.026 & 0.156 & 0.345 \\ \cline{2-8}
\textbf{Cover} & Std & 0.419 & 0.45 & 0.109 & 0.036 & 0.141 & 0.148 \\
\hline
\textbf{Base} & mean & 0.437 & 0.494 & 0.192 & 0.227 & 0.316 & 0.04 \\ \cline{2-8}
\textbf{Board} & Std & 0.039 & 0.107 & 0.009 & 0.039 & 0.101 & 0.109 \\
\hline
\end{tabular}
\caption{Performance comparison with different number of
samples collected over different time length.}
\end{table}

\begin{figure}[t!]
\centering
\includegraphics[width=0.4\textwidth]{bayesian_result.png}
\caption{Captured 3D point clouds of PCB and base board for pose
estimation test.}
\end{figure}
\bibliography{mybib}
\bibliographystyle{IEEETran}

%\begin{thebibliography}{00}
%
%\bibitem{b1} G. O. Young, ``Synthetic structure of industrial plastics,'' in \emph{Plastics,} 2\textsuperscript{nd} ed., vol. 3, J. Peters, Ed. New York, NY, USA: McGraw-Hill, 1964, pp. 15--64.
%
%\bibitem{b2} W.-K. Chen, \emph{Linear Networks and Systems.} Belmont, CA, USA: Wadsworth, 1993, pp. 123--135.
%
%\bibitem{b3} J. U. Duncombe, ``Infrared navigation---Part I: An assessment of feasibility,'' \emph{IEEE Trans. Electron Devices}, vol. ED-11, no. 1, pp. 34--39, Jan. 1959, 10.1109/TED.2016.2628402.
%
%\bibitem{b4} E. P. Wigner, ``Theory of traveling-wave optical laser,'' \emph{Phys. Rev}., vol. 134, pp. A635--A646, Dec. 1965.
%
%\bibitem{b5} E. H. Miller, ``A note on reflector arrays,'' \emph{IEEE Trans. Antennas Propagat}., to be published.
%
%\bibitem{b6} E. E. Reber, R. L. Michell, and C. J. Carter, ``Oxygen absorption in the earth's atmosphere,'' Aerospace Corp., Los Angeles, CA, USA, Tech. Rep. TR-0200 (4230-46)-3, Nov. 1988.
%
%\bibitem{b7} J. H. Davis and J. R. Cogdell, ``Calibration program for the 16-foot antenna,'' Elect. Eng. Res. Lab., Univ. Texas, Austin, TX, USA, Tech. Memo. NGL-006-69-3, Nov. 15, 1987.
%
%\bibitem{b8} \emph{Transmission Systems for Communications}, 3\textsuperscript{rd} ed., Western Electric Co., Winston-Salem, NC, USA, 1985, pp. 44--60.
%
%\bibitem{b9} \emph{Motorola Semiconductor Data Manual}, Motorola Semiconductor Products Inc., Phoenix, AZ, USA, 1989.
%
%\bibitem{b10} G. O. Young, ``Synthetic structure of industrial
%plastics,'' in Plastics, vol. 3, Polymers of Hexadromicon, J. Peters,
%Ed., 2\textsuperscript{nd} ed. New York, NY, USA: McGraw-Hill, 1964, pp. 15-64.
%[Online]. Available:
%\underline{http://www.bookref.com}.
%
%\bibitem{b11} \emph{The Founders' Constitution}, Philip B. Kurland
%and Ralph Lerner, eds., Chicago, IL, USA: Univ. Chicago Press, 1987.
%[Online]. Available: \underline{http://press-pubs.uchicago.edu/founders/}
%
%\bibitem{b12} The Terahertz Wave eBook. ZOmega Terahertz Corp., 2014.
%[Online]. Available:
%\underline{http://dl.z-thz.com/eBook/zomega\_ebook\_pdf\_1206\_sr.pdf}. Accessed on: May 19, 2014.
%
%\bibitem{b13} Philip B. Kurland and Ralph Lerner, eds., \emph{The
%Founders' Constitution.} Chicago, IL, USA: Univ. of Chicago Press,
%1987, Accessed on: Feb. 28, 2010, [Online] Available:
%\underline{http://press-pubs.uchicago.edu/founders/}
%
%\bibitem{b14} J. S. Turner, ``New directions in communications,'' \emph{IEEE J. Sel. Areas Commun}., vol. 13, no. 1, pp. 11-23, Jan. 1995.
%
%\bibitem{b15} W. P. Risk, G. S. Kino, and H. J. Shaw, ``Fiber-optic frequency shifter using a surface acoustic wave incident at an oblique angle,'' \emph{Opt. Lett.}, vol. 11, no. 2, pp. 115--117, Feb. 1986.
%
%\bibitem{b16} P. Kopyt \emph{et al., ``}Electric properties of graphene-based conductive layers from DC up to terahertz range,'' \emph{IEEE THz Sci. Technol.,} to be published. DOI: 10.1109/TTHZ.2016.2544142.
%
%\bibitem{b17} PROCESS Corporation, Boston, MA, USA. Intranets:
%Internet technologies deployed behind the firewall for corporate
%productivity. Presented at INET96 Annual Meeting. [Online].
%Available: \underline{http://home.process.com/Intranets/wp2.htp}
%
%\bibitem{b18} R. J. Hijmans and J. van Etten, ``Raster: Geographic analysis and modeling with raster data,'' R Package Version 2.0-12, Jan. 12, 2012. [Online]. Available: \underline {http://CRAN.R-project.org/package=raster} 
%
%\bibitem{b19} Teralyzer. Lytera UG, Kirchhain, Germany [Online].
%Available:
%\underline{http://www.lytera.de/Terahertz\_THz\_Spectroscopy.php?id=home}, Accessed on: Jun. 5, 2014
%
%\bibitem{b20} U.S. House. 102\textsuperscript{nd} Congress, 1\textsuperscript{st} Session. (1991, Jan. 11). \emph{H. Con. Res. 1, Sense of the Congress on Approval of}  \emph{Military Action}. [Online]. Available: LEXIS Library: GENFED File: BILLS
%
%\bibitem{b21} Musical toothbrush with mirror, by L.M.R. Brooks. (1992, May 19). Patent D 326 189 [Online]. Available: NEXIS Library: LEXPAT File: DES
%
%\bibitem{b22} D. B. Payne and J. R. Stern, ``Wavelength-switched pas- sively coupled single-mode optical network,'' in \emph{Proc. IOOC-ECOC,} Boston, MA, USA, 1985, pp. 585--590.
%
%\bibitem{b23} D. Ebehard and E. Voges, ``Digital single sideband detection for interferometric sensors,'' presented at the \emph{2\textsuperscript{nd} Int. Conf. Optical Fiber Sensors,} Stuttgart, Germany, Jan. 2-5, 1984.
%
%\bibitem{b24} G. Brandli and M. Dick, ``Alternating current fed power supply,'' U.S. Patent 4 084 217, Nov. 4, 1978.
%
%\bibitem{b25} J. O. Williams, ``Narrow-band analyzer,'' Ph.D. dissertation, Dept. Elect. Eng., Harvard Univ., Cambridge, MA, USA, 1993.
%
%\bibitem{b26} N. Kawasaki, ``Parametric study of thermal and chemical nonequilibrium nozzle flow,'' M.S. thesis, Dept. Electron. Eng., Osaka Univ., Osaka, Japan, 1993.
%
%\bibitem{b27} A. Harrison, private communication, May 1995.
%
%\bibitem{b28} B. Smith, ``An approach to graphs of linear forms,'' unpublished.
%
%\bibitem{b29} A. Brahms, ``Representation error for real numbers in binary computer arithmetic,'' IEEE Computer Group Repository, Paper R-67-85.
%
%\bibitem{b30} IEEE Criteria for Class IE Electric Systems, IEEE Standard 308, 1969.
%
%\bibitem{b31} Letter Symbols for Quantities, ANSI Standard Y10.5-1968.
%
%\bibitem{b32} R. Fardel, M. Nagel, F. Nuesch, T. Lippert, and A. Wokaun, ``Fabrication of organic light emitting diode pixels by laser-assisted forward transfer,'' \emph{Appl. Phys. Lett.}, vol. 91, no. 6, Aug. 2007, Art. no. 061103.~
%
%\bibitem{b33} J. Zhang and N. Tansu, ``Optical gain and laser characteristics of InGaN quantum wells on ternary InGaN substrates,'' \emph{IEEE Photon. J.}, vol. 5, no. 2, Apr. 2013, Art. no. 2600111
%
%\bibitem{b34} S. Azodolmolky~\emph{et al.}, Experimental demonstration of an impairment aware network planning and operation tool for transparent/translucent optical networks,''~\emph{J. Lightw. Technol.}, vol. 29, no. 4, pp. 439--448, Sep. 2011.
%
%\end{thebibliography}

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{me.png}}]{Hecheng Zhao} received the B.S. degree
in Automation from
the Nanjing University of Posts and Telecommunications,
Nanjing, China, in 2015. He is currently pursuing the M.S. degree in AI and Robotics with Sungkyunkwan University,
Suwon, South Korea.
His research interests include SLAM, machine learning, and computer vision.
\end{IEEEbiography}

\begin{IEEEbiography}[{\includegraphics[width=1in,height=1.25in,clip,keepaspectratio]{lee.png}}]{Sukhan Lee}  received the B.S. and M.S. degrees
in electrical engineering from Seoul National
University, South Korea, in 1972 and 1974, respectively, and the Ph.D. degree in electrical engineering from Purdue University, West Lafayette, IN,
USA, in 1982.
From 1983 to 1997, he was with the Departments of Electrical Engineering and of Computer
Science, University of Southern California. From
1990 to 1997, he was with the Jet Propulsion
Laboratory, California Institute of Technology, as a Senior Member of the
Technical Staff. From 1998 to 2003, he was the Executive Vice President,
and also the Chief Research Officer with the Samsung Advanced Institute
of Technology. He has been working as a Professor of information and
communication engineering and WCU Professor of interaction science with
Sungkyunkwan University, since 2003. He was designated the Dean of the
Graduate School of Sungkyunkwan University, in 2011.He is also serving
as the Director of the Intelligent Systems Research Institute. His research
interests are in the areas of cognitive robotics, intelligent systems, and
micro/nano electro-mechanical systems.
Dr. Lee is currently a Fellow of the Korean National Academy of Science
and Technology.
\end{IEEEbiography}

\EOD

\end{document}
